{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import os\n",
    "from typing import Dict, Iterable, List, Tuple\n",
    "import faiss\n",
    "from embedding import embedding\n",
    "from collections import defaultdict\n",
    "from langchain_core.documents import Document\n",
    "from document_processor import _load_local_documents, split_documents_to_text_chunks\n",
    "import numpy as np\n",
    "from config import (\n",
    "    DEFAULT_BATCH_SIZE,\n",
    "    EMBEDDING_DIM,\n",
    "    VECTOR_INDEX_PATH,\n",
    "    META_PATH,\n",
    "    DEFAULT_TOP_K,\n",
    "    TEST_PDFS_DIR,\n",
    ")\n",
    "\n",
    "\n",
    "def _batched(items: List[str], batch_size: int) -> Iterable[List[str]]:\n",
    "    \"\"\"\n",
    "    Yield successive n-sized chunks from items for batch processing.\n",
    "    \"\"\"\n",
    "    for i in range(0, len(items), batch_size):\n",
    "        yield items[i:i + batch_size]\n",
    "\n",
    "\n",
    "def _embed_texts(texts: List[str], batch_size: int = DEFAULT_BATCH_SIZE) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Returns float32 matrix: (n, EMBEDDING_DIM)\n",
    "    \"\"\"\n",
    "    vectors: List[np.ndarray] = []\n",
    "    for batch in _batched(texts, batch_size=batch_size):\n",
    "        try:\n",
    "            batch_vecs = embedding(batch)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(\n",
    "                \"Embedding request failed. Check `EMBEDDING_URL` in `embedding.py` \"\n",
    "                \"and that the service is reachable.\"\n",
    "            ) from e\n",
    "\n",
    "        arr = np.asarray(batch_vecs, dtype=\"float32\")\n",
    "        if arr.ndim != 2 or arr.shape[1] != EMBEDDING_DIM:\n",
    "            raise ValueError(f\"Expected embeddings shape (n, {EMBEDDING_DIM}), got {arr.shape}\")\n",
    "        vectors.append(arr)\n",
    "\n",
    "    vectors = np.vstack(vectors).astype(\"float32\", copy=False)\n",
    "    return vectors\n",
    "\n",
    "\n",
    "class FaissManager:\n",
    "    def __init__(self, index_path: str = VECTOR_INDEX_PATH, meta_path: str = META_PATH):\n",
    "        self.index_path = index_path\n",
    "        self.meta_path = meta_path\n",
    "\n",
    "        if os.path.exists(index_path) and os.path.exists(meta_path):\n",
    "            self.index = faiss.read_index(index_path)\n",
    "            self.meta = self.load_meta()\n",
    "        else:  # create new index\n",
    "            self.index = FaissManager.create_index()\n",
    "            # inside chunks, key: chunk_id (str), value: (text, file_name)\n",
    "            self.meta = {\"next_id\": 0, \"files\": defaultdict(list), \"chunks\": dict()}\n",
    "\n",
    "    @staticmethod\n",
    "    def create_index(dim: int = EMBEDDING_DIM) -> faiss.IndexFlatIP:\n",
    "        base = faiss.IndexFlatIP(dim)\n",
    "        return faiss.IndexIDMap2(base)\n",
    "\n",
    "    def load_index(self) -> faiss.Index:\n",
    "        return faiss.read_index(self.index_path)\n",
    "\n",
    "    def save_index(self) -> None:\n",
    "        # in case the config changes, and the new directory doesn't exist\n",
    "        os.makedirs(os.path.dirname(self.index_path), exist_ok=True)\n",
    "        faiss.write_index(self.index, self.index_path)\n",
    "\n",
    "    def load_meta(self) -> Dict:\n",
    "        with open(self.meta_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            meta = json.load(f)\n",
    "        return meta\n",
    "\n",
    "    def save_meta(self) -> None:\n",
    "        # in case the config changes, and the new directory doesn't exist\n",
    "        os.makedirs(os.path.dirname(self.meta_path), exist_ok=True)\n",
    "        with open(self.meta_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            # indent=2 for readability, ensure_ascii=False for unicode support\n",
    "            json.dump(self.meta, file, ensure_ascii=False, indent=2)\n",
    "\n",
    "    def save(self) -> None:\n",
    "        self.save_index()\n",
    "        self.save_meta()\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        \"\"\"\n",
    "        Clear the FAISS index and metadata.\n",
    "        \"\"\"\n",
    "        if os.path.exists(self.index_path):\n",
    "            os.remove(self.index_path)\n",
    "        if os.path.exists(self.meta_path):\n",
    "            os.remove(self.meta_path)\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        \"\"\"\n",
    "        Clear the saved index and meta file, then reset the FAISS index and metadata to initial state.\n",
    "        \"\"\"\n",
    "        self.clear()\n",
    "        self.index.reset()\n",
    "        self.meta = {\"next_id\": 0, \"files\": defaultdict(list), \"chunks\": dict()}\n",
    "\n",
    "    def add_chunks(self, chunks: List[Document]) -> Tuple[faiss.Index, Dict[int, str]]:\n",
    "        \"\"\"\n",
    "        Add new texts to the FAISS index.\n",
    "        \"\"\"\n",
    "        if not chunks:\n",
    "            return\n",
    "        texts = [chunk.page_content for chunk in chunks if chunk.page_content]\n",
    "        file_names = [chunk.metadata.get(\"file_name\", \"unknown\") for chunk in chunks if chunk.page_content]\n",
    "\n",
    "        vectors = _embed_texts(texts)\n",
    "        faiss.normalize_L2(vectors)  # in-place L2 normalization\n",
    "\n",
    "        start_id = self.meta[\"next_id\"]\n",
    "        self.meta[\"next_id\"] += len(texts)\n",
    "        ids = np.arange(start_id, start_id + len(texts)).astype(\"int64\")\n",
    "\n",
    "        self.index.add_with_ids(vectors, ids)\n",
    "        for i, t, f in zip(ids.tolist(), texts, file_names):\n",
    "            self.meta[\"chunks\"][str(i)] = (t, f)\n",
    "            self.meta[\"files\"][f].append(i)\n",
    "\n",
    "    def search(self, query: str, top_k: int = DEFAULT_TOP_K) -> List[Dict[str, object]]:\n",
    "        \"\"\"\n",
    "        Perform a top k similarity search in the FAISS index.\n",
    "        \"\"\"\n",
    "        q_vec = _embed_texts([query])\n",
    "        faiss.normalize_L2(q_vec)\n",
    "\n",
    "        scores, ids = self.index.search(q_vec, top_k)  # a KNN search\n",
    "        out: List[Dict[str, object]] = []\n",
    "        for score, _id in zip(scores[0].tolist(), ids[0].tolist()):\n",
    "            # when FAISS doesn't have enough results to fill top_k, it pads score and id with -1\n",
    "            if _id != -1:\n",
    "                text_chunk, file_name = self.meta[\"chunks\"].get(str(_id), (\"\", \"\"))\n",
    "                out.append({\"id\": int(_id), \"score\": float(score), \"file_name\": file_name, \"text\": text_chunk})\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-15T00:37:07.793161Z",
     "start_time": "2026-01-15T00:37:03.971478Z"
    }
   },
   "id": "e4625a1dcb23f7ba",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "index_manager = FaissManager()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-15T00:37:10.135304Z",
     "start_time": "2026-01-15T00:37:10.128125Z"
    }
   },
   "id": "3abddfdb6bdf0bdb",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'TrainingLanguageModelsToFollowInstructionsWithHumanFeedback.pdf': [24,\n  25,\n  26,\n  27,\n  28,\n  29,\n  30,\n  31,\n  32,\n  33,\n  34,\n  35,\n  36,\n  37,\n  38,\n  39,\n  40,\n  41,\n  42,\n  43,\n  44,\n  45,\n  46,\n  47,\n  48,\n  49,\n  50,\n  51,\n  52,\n  53,\n  54,\n  55,\n  56,\n  57,\n  58,\n  59,\n  60,\n  61,\n  62,\n  63,\n  64,\n  65,\n  66,\n  67,\n  68,\n  69,\n  70,\n  71,\n  72,\n  73,\n  74,\n  75,\n  76,\n  77,\n  78,\n  79,\n  80,\n  81,\n  82,\n  83,\n  84,\n  85,\n  86,\n  87,\n  88,\n  89,\n  90,\n  91,\n  92,\n  93,\n  94,\n  95,\n  96,\n  97,\n  98,\n  99,\n  100,\n  101,\n  102,\n  103,\n  104,\n  105,\n  106,\n  107,\n  108,\n  109,\n  110,\n  111,\n  112,\n  113,\n  114,\n  115,\n  116,\n  117,\n  118,\n  119,\n  120,\n  121,\n  122,\n  123,\n  124,\n  125,\n  126,\n  127,\n  128,\n  129,\n  130,\n  131,\n  132,\n  133,\n  134,\n  135]}"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_manager.meta['files']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-15T00:37:23.489187Z",
     "start_time": "2026-01-15T00:37:23.484412Z"
    }
   },
   "id": "d5ecaefa7ec64497",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "112"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_manager.index.ntotal"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-15T00:37:39.567816Z",
     "start_time": "2026-01-15T00:37:39.564651Z"
    }
   },
   "id": "723a78973f0f02a0",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\DAHOU\\Business\\go_tech\\chat-pdf\\data\\test_data\\AttentionIsAllYouNeed.pdf\n",
      "C:\\DAHOU\\Business\\go_tech\\chat-pdf\\data\\test_data\\TrainingLanguageModelsToFollowInstructionsWithHumanFeedback.pdf\n",
      "Loaded 2 document(s) from 'C:\\DAHOU\\Business\\go_tech\\chat-pdf\\data\\test_data'\n"
     ]
    }
   ],
   "source": [
    "index_manager = FaissManager()\n",
    "test_documents = _load_local_documents(TEST_PDFS_DIR)\n",
    "test_chunks = split_documents_to_text_chunks(test_documents)\n",
    "index_manager.add_chunks(test_chunks)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-15T00:04:49.780608Z",
     "start_time": "2026-01-15T00:04:42.789268Z"
    }
   },
   "id": "bad0d882f5207704",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "136"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_manager.index.ntotal"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-15T00:04:49.788707Z",
     "start_time": "2026-01-15T00:04:49.782185Z"
    }
   },
   "id": "8d377ca83064c1bf",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "index_manager.meta['files']['AttentionIsAllYouNeed.pdf']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de33c2f15ccbeac",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "24"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_to_remove = np.array(index_manager.meta['files']['AttentionIsAllYouNeed.pdf'], dtype=np.int64)\n",
    "index_manager.index.remove_ids(faiss.IDSelectorBatch(ids_to_remove))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-15T00:06:12.224497Z",
     "start_time": "2026-01-15T00:06:12.219432Z"
    }
   },
   "id": "9d9b94e97f1743d",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "112"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_manager.index.ntotal"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-15T00:06:12.857498Z",
     "start_time": "2026-01-15T00:06:12.852709Z"
    }
   },
   "id": "adb799d199c3142",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "remaining_ids = faiss.vector_to_array(index_manager.index.id_map)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-15T00:07:37.395939Z",
     "start_time": "2026-01-15T00:07:37.393213Z"
    }
   },
   "id": "fd4b2278e62cbac8",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "np.int64(135)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remaining_ids[-1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-15T00:08:55.062299Z",
     "start_time": "2026-01-15T00:08:55.058865Z"
    }
   },
   "id": "521191f33b41c256",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_query = \"What is natural language processing?\"\n",
    "results = index_manager.search(test_query, top_k=5)\n",
    "print(f\"Query: {test_query}\")\n",
    "for r in results:\n",
    "    print(f\"--------------------------------\\nscore: {r['score']}, file name: {r['file_name']}\\n\")\n",
    "    print(f\"--------------------------------\\n{r['text'][:100]}\\n\")  # print first 100 chars of each result\n",
    "\n",
    "index_manager.clear()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1534acdfdd3afd1d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "272"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "224+48"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-15T00:05:40.509278Z",
     "start_time": "2026-01-15T00:05:40.505296Z"
    }
   },
   "id": "174f264d7731c1ac",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "98920d711517c877"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3a2483a383fdb700"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1f994f94f228b354"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
